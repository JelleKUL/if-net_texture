{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "Processing the shapenet dataset to be compatible with if-net texture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the folders and identifiers\n",
    "\n",
    "Shapenet has a different folder system, where each mesh is in a subfolder, in this first step, we find each unique identifier of the models and create new folders at the desired location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import trimesh\n",
    "import data_processing.utils as utils\n",
    "import data_processing.mesharray as mesharray\n",
    "import config.config_loader as cfg_loader\n",
    "import glob\n",
    "\n",
    "# The location of the original dataset\n",
    "datasetLocation = Path(\"../../datasets/ShapeNet/03001627\")\n",
    "# The desired output location for the processed dataset\n",
    "datasetOutFolder = Path(\"dataset/SHARP2020/shapenet\")\n",
    "# The config file\n",
    "configFilePath = Path(\"projects/if-net_texture/config/SHARP2020/shapenet.yaml\")\n",
    "\n",
    "utils.make_dir_if_not_exist(datasetOutFolder)\n",
    "utils.make_dir_if_not_exist(datasetOutFolder/ \"test\")\n",
    "utils.make_dir_if_not_exist(datasetOutFolder/ \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for all obj files\n",
    "path = datasetLocation / \"**\" / \"*.obj\"\n",
    "print(\"Looking for all files that match: \" + str(path))\n",
    "files = glob.glob(str(path), recursive=True)\n",
    "print(\"Found \" + str(len(files)) + \" files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = cfg_loader.load(configFilePath)\n",
    "\n",
    "# shorthands\n",
    "trainTestRatio =  cfg[\"preprossesing\"][\"trainTestRatio\"]\n",
    "bbox = cfg['data_bounding_box']\n",
    "res = cfg['input_resolution']\n",
    "num_points = cfg['input_points_number']\n",
    "bbox_str = cfg['data_bounding_box_str']\n",
    "grid_points = utils.create_grid_points_from_xyz_bounds(*bbox, res)\n",
    "kdtree = KDTree(grid_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the processed files\n",
    "\n",
    "1) Load the trimesh scene\n",
    "2) sample each submesh into a separate pointcloud\n",
    "3) Combine them into one big material pointcloud\n",
    "4) Resample to theset number of points\n",
    "5) cut random holes in the point cloud by selecting nearest neighbours\n",
    "6) Save the complete sampled shape as a npz file\n",
    "    > id/id_normalized_color_samples100000_bbox-0.8,0.8,-0.15,2.1,-0.8,0.8.npz\n",
    "7) save 4 variations in the same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrOfFiles = 100 #len(files)\n",
    "trainCases = int(np.round(nrOfFiles * trainTestRatio))\n",
    "\n",
    "for i in range(nrOfFiles):\n",
    "    print(\"Processing \" + str(i) + \"/\" + str(nrOfFiles))\n",
    "    objFile = files[i]\n",
    "    newId = Path(objFile).parent.parent.name\n",
    "    # Make the new destination folder for the files\n",
    "    if(i < trainCases):\n",
    "        newIdPath = datasetOutFolder / \"train\" / newId\n",
    "    else:\n",
    "        newIdPath = datasetOutFolder / \"test\" / newId\n",
    "    utils.make_dir_if_not_exist(newIdPath)\n",
    "    \n",
    "    # Create a new mesharray object to parse the data\n",
    "    meshArray = mesharray.MeshArray(\n",
    "        id = newId, \n",
    "        bbox=bbox, \n",
    "        kdtree = kdtree,\n",
    "        grid_points=grid_points, \n",
    "        num_points=num_points ).from_trimesh(objFile)\n",
    "\n",
    "    # Save the full point cloud as a colored point cloud\n",
    "    meshArray.savez(newIdPath / (newId + \"_normalized_color_samples\" + str(num_points) + \"_bbox\" + bbox_str + \".npz\"))\n",
    "    # Create a number of incomplete meshes and save them as voxelised point clouds for standardisation\n",
    "    meshArray.filter_points(newIdPath, 4, 4, 2e-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
